# -*- coding: utf-8 -*-
"""ANNipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ACeZlhK5JsZRKPgd9kjExLamTAgIJlCD
"""

pip install tensorflow

nvcc --version

pip install --upgrade pip setuptools wheel

pip uninstall tensorflow-gpu tensorflow -y

pip install tensorflow==2.12.0

import tensorflow as tf
print("Num GPUs Available: ", len(tf.config.experimental.list_physical_devices('GPU')))
print(tf.__version__)

import numpy as np
import matplotlib.pyplot as plt
import pandas as pd

df=pd.read_csv('Churn_Modelling.csv')
df.head()

x=df.iloc[:,3:13]
y=df.iloc[:,13]

x.head()

y

pd.get_dummies(x['Geography'])

geography=pd.get_dummies(x['Geography'],drop_first=True)
gender=pd.get_dummies(x['Gender'],drop_first=True)

x=x.drop(['Geography','Gender'],axis = 1)
x.head()

x=pd.concat([x,geography,gender],axis = 1)

#Splitted the dataset into Training and Testing

from sklearn.model_selection import train_test_split
x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.2,random_state=0)

#Feature Scaling

from sklearn.preprocessing import StandardScaler
sc = StandardScaler()
x_train = sc.fit_transform(x_train)
x_test = sc.transform(x_test)

x_train

x_test

x_train.shape

# Part 2 create the ANN

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
from tensorflow.keras.layers import LeakyReLU,PReLU,ELU,ReLU
from tensorflow.keras.layers import Dropout

## Lets initialize the ANN
classifier = Sequential()

#adding the input Layer
classifier.add(Dense(units=11,activation='relu'))

#adding the first hidden Layer
classifier.add(Dense(units=7,activation='relu'))

#adding the second hidden Layer
classifier.add(Dense(units=6,activation='relu'))

#Adding the output Layer
classifier.add(Dense(1,activation='sigmoid'))

classifier.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])

import tensorflow
opt=tensorflow.keras.optimizers.Adam(learning_rate=0.01)

## Early Stopping
import tensorflow as tf
early_stopping=tf.keras.callbacks.EarlyStopping(
    monitor="val_loss",
    min_delta=0.0001,
    patience=20,
    verbose=1,
    mode="auto",
    baseline=None,
    restore_best_weights=False,
)

model_history=classifier.fit(x_train,y_train,validation_split=0.33,batch_size=10,epochs=1000,callbacks=early_stopping)

model_history.history.keys()

# summerize history for accuracy
import matplotlib.pyplot as plt

plt.plot(model_history.history['accuracy'])
plt.plot(model_history.history['val_accuracy'])
plt.title('model accuracy')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['train','test'], loc='upper left')
plt.show()

# summerize history for loss
plt.plot(model_history.history['loss'])
plt.plot(model_history.history['val_loss'])
plt.title('model loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train','test'], loc='upper left')
plt.show()

# Parrt 3 - Making the predictions and evaluating the model

#predicting the Test set results
y_pred = classifier.predict(x_test)
y_pred = (y_pred>=0.5)

# make the confusion matrix
 from sklearn.metrics import confusion_matrix
 cm = confusion_matrix(y_test,y_pred)
 cm

from sklearn.metrics import accuracy_score
score=accuracy_score(y_pred,y_test)

score

#get the weights
classifier.get_weights()

